{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías necesarias\n",
    "import pandas as pd\n",
    "import json\n",
    "import random\n",
    "\n",
    "# Cargar el archivo credits.csv\n",
    "credits = pd.read_csv(\"credits.csv\", low_memory=False)\n",
    "\n",
    "# Función para expandir columnas JSON en múltiples filas\n",
    "def expand_json_column(df, column_name, id_column):\n",
    "    \"\"\"Expande una columna JSON almacenada como string en nuevas filas.\"\"\"\n",
    "    expanded_data = []\n",
    "    for _, row in df.iterrows():\n",
    "        try:\n",
    "            json_list = json.loads(row[column_name].replace(\"'\", \"\\\"\")) if pd.notna(row[column_name]) else []\n",
    "            for item in json_list:\n",
    "                item_data = item.copy()\n",
    "                item_data[id_column] = row[id_column]\n",
    "                expanded_data.append(item_data)\n",
    "        except json.JSONDecodeError:\n",
    "            continue\n",
    "\n",
    "    return pd.DataFrame(expanded_data)\n",
    "\n",
    "# Asegurar que 'cast' es string y manejar valores NaN\n",
    "credits['cast'] = credits['cast'].astype(str).fillna('[]')\n",
    "\n",
    "# Expandir la columna JSON 'cast' desde credits.csv\n",
    "actors_expanded = expand_json_column(credits, 'cast', 'id')\n",
    "\n",
    "# Seleccionar solo las columnas necesarias y eliminar duplicados\n",
    "actors_cleaned = actors_expanded[['cast_id', 'name', 'gender', 'character', 'id']].drop_duplicates()\n",
    "actors_cleaned.rename(columns={\n",
    "    'cast_id': 'ActorID',\n",
    "    'name': 'Name',\n",
    "    'gender': 'Gender',\n",
    "    'character': 'Role',\n",
    "    'id': 'MovieID'  # Relación con la película\n",
    "}, inplace=True)\n",
    "\n",
    "# Generar fechas de nacimiento ficticias para los actores (entre 1950 y 2005)\n",
    "random.seed(42)\n",
    "actors_cleaned['Born_Date'] = [random.randint(1950, 2005) for _ in range(len(actors_cleaned))]\n",
    "\n",
    "# Guardar el CSV de actores\n",
    "actor_csv_path = \"Actor_LIMPIO.csv\"\n",
    "actors_cleaned.to_csv(actor_csv_path, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un nuevo identificador único para cada actor basado en su nombre\n",
    "actors_cleaned['ActorID'] = actors_cleaned['Name'].astype('category').cat.codes\n",
    "\n",
    "# Volver a guardar el CSV con el nuevo identificador único\n",
    "actor_csv_path = \"Actor_LIMPIO2.csv\"\n",
    "actors_cleaned.to_csv(actor_csv_path, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los archivos necesarios\n",
    "movies = pd.read_csv(\"movies_metadata.csv\", low_memory=False)\n",
    "keywords = pd.read_csv(\"keywords.csv\", low_memory=False)\n",
    "\n",
    "# Seleccionar solo las columnas necesarias de movies_metadata\n",
    "movies_selected = movies[['id', 'title', 'release_date', 'runtime', 'popularity']].copy()\n",
    "\n",
    "# Renombrar columnas según el esquema\n",
    "movies_selected.rename(columns={\n",
    "    'id': 'MovieID',\n",
    "    'title': 'Title',\n",
    "    'release_date': 'Release_Date',\n",
    "    'runtime': 'Runtime',\n",
    "    'popularity': 'Popularity'\n",
    "}, inplace=True)\n",
    "\n",
    "# Limpiar valores nulos o incorrectos\n",
    "movies_selected['Release_Date'] = pd.to_datetime(movies_selected['Release_Date'], errors='coerce')  # Convertir a fecha\n",
    "movies_selected['Runtime'] = pd.to_numeric(movies_selected['Runtime'], errors='coerce').fillna(0)  # Convertir a numérico\n",
    "movies_selected['Popularity'] = pd.to_numeric(movies_selected['Popularity'], errors='coerce').fillna(0)  # Convertir a numérico\n",
    "\n",
    "# Asegurar que 'id' en keywords es string para evitar errores al unir\n",
    "keywords['id'] = keywords['id'].astype(str)\n",
    "movies_selected['MovieID'] = movies_selected['MovieID'].astype(str)\n",
    "\n",
    "# Unir keywords con movies_metadata usando MovieID\n",
    "movies_final = movies_selected.merge(keywords[['id', 'keywords']], left_on='MovieID', right_on='id', how='left')\n",
    "movies_final.drop(columns=['id'], inplace=True)  # Eliminar columna redundante\n",
    "\n",
    "# Renombrar la columna de keywords\n",
    "movies_final.rename(columns={'keywords': 'Keywords'}, inplace=True)\n",
    "\n",
    "# Guardar el CSV de películas actualizado\n",
    "movie_csv_path = \"Movie_LIMPIO2.csv\"\n",
    "movies_final.to_csv(movie_csv_path, index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para extraer solo los nombres de keywords desde JSON\n",
    "def extract_keyword_names(json_str):\n",
    "    \"\"\"Extrae solo los nombres de las keywords desde un string JSON.\"\"\"\n",
    "    try:\n",
    "        keywords_list = json.loads(json_str.replace(\"'\", \"\\\"\")) if pd.notna(json_str) else []\n",
    "        return \", \".join([kw[\"name\"] for kw in keywords_list])  # Convertir a string separado por comas\n",
    "    except json.JSONDecodeError:\n",
    "        return \"\"\n",
    "\n",
    "# Aplicar la función a la columna de keywords\n",
    "movies_final['Keywords'] = movies_final['Keywords'].astype(str).apply(extract_keyword_names)\n",
    "\n",
    "# Guardar el CSV corregido\n",
    "movie_csv_path = \"Movie_LIMPIO3.csv\"\n",
    "movies_final.to_csv(movie_csv_path, index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías necesarias\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Cargar los archivos necesarios\n",
    "movies = pd.read_csv(\"movies_metadata.csv\", low_memory=False)\n",
    "keywords = pd.read_csv(\"keywords.csv\", low_memory=False)\n",
    "\n",
    "# Seleccionar solo las columnas necesarias de movies_metadata\n",
    "movies_selected = movies[['id', 'title', 'release_date', 'runtime', 'popularity']].copy()\n",
    "\n",
    "# Renombrar columnas según el esquema\n",
    "movies_selected.rename(columns={\n",
    "    'id': 'MovieID',\n",
    "    'title': 'Title',\n",
    "    'release_date': 'Release_Date',\n",
    "    'runtime': 'Runtime',\n",
    "    'popularity': 'Popularity'\n",
    "}, inplace=True)\n",
    "\n",
    "# Limpiar valores nulos o incorrectos\n",
    "movies_selected['Release_Date'] = pd.to_datetime(movies_selected['Release_Date'], errors='coerce')  # Convertir a fecha\n",
    "movies_selected['Runtime'] = pd.to_numeric(movies_selected['Runtime'], errors='coerce').fillna(0)  # Convertir a numérico\n",
    "movies_selected['Popularity'] = pd.to_numeric(movies_selected['Popularity'], errors='coerce').fillna(0)  # Convertir a numérico\n",
    "\n",
    "# Verificar el formato de los IDs en ambos archivos\n",
    "keywords['id'] = keywords['id'].astype(str)\n",
    "movies_selected['MovieID'] = movies_selected['MovieID'].astype(str)\n",
    "\n",
    "# Unir keywords con movies_metadata usando MovieID\n",
    "movies_final = movies_selected.merge(keywords, left_on='MovieID', right_on='id', how='left')\n",
    "\n",
    "# Función para extraer solo los nombres de keywords desde JSON\n",
    "def extract_keyword_names(json_str):\n",
    "    \"\"\"Extrae solo los nombres de las keywords desde un string JSON.\"\"\"\n",
    "    try:\n",
    "        keywords_list = json.loads(json_str.replace(\"'\", \"\\\"\")) if pd.notna(json_str) else []\n",
    "        return \", \".join([kw[\"name\"] for kw in keywords_list])  # Convertir a string separado por comas\n",
    "    except json.JSONDecodeError:\n",
    "        return \"\"\n",
    "\n",
    "# Aplicar la función a la columna de keywords\n",
    "movies_final['keywords'] = movies_final['keywords'].fillna('[]').astype(str)\n",
    "movies_final['keywords'] = movies_final['keywords'].apply(extract_keyword_names)\n",
    "\n",
    "# Renombrar la columna de keywords\n",
    "movies_final.rename(columns={'keywords': 'Keywords'}, inplace=True)\n",
    "\n",
    "# Eliminar la columna 'id' redundante después del merge\n",
    "movies_final.drop(columns=['id'], inplace=True)\n",
    "\n",
    "# Guardar el CSV corregido\n",
    "movie_csv_path = \"Movie_LIMPIO4.csv\"\n",
    "movies_final.to_csv(movie_csv_path, index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Director"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el archivo credits.csv\n",
    "credits = pd.read_csv(\"credits.csv\")\n",
    "\n",
    "# Extraer solo las filas donde la persona tiene el rol de \"Director\" en la columna crew\n",
    "credits['crew'] = credits['crew'].fillna('[]')\n",
    "\n",
    "# Función para extraer directores desde JSON\n",
    "def extract_directors(json_str, movie_id):\n",
    "    \"\"\"Extrae directores desde la columna crew en formato JSON.\"\"\"\n",
    "    try:\n",
    "        crew_list = json.loads(json_str.replace(\"'\", \"\\\"\")) if pd.notna(json_str) else []\n",
    "        return [\n",
    "            {\"DirectorID\": crew[\"id\"], \"Name\": crew[\"name\"], \"Gender\": crew[\"gender\"], \"MovieID\": movie_id}\n",
    "            for crew in crew_list if crew.get(\"job\") == \"Director\"\n",
    "        ]\n",
    "    except json.JSONDecodeError:\n",
    "        return []\n",
    "\n",
    "# Aplicar la función a todas las filas del DataFrame\n",
    "directors_data = []\n",
    "for _, row in credits.iterrows():\n",
    "    directors_data.extend(extract_directors(row['crew'], row['id']))\n",
    "\n",
    "# Convertir la lista de directores en un DataFrame\n",
    "directors_cleaned = pd.DataFrame(directors_data)\n",
    "\n",
    "# Agregar columna de edad inventada (entre 30 y 75 años)\n",
    "import numpy as np\n",
    "np.random.seed(42)  # Para reproducibilidad\n",
    "directors_cleaned['Age'] = np.random.randint(30, 75, size=len(directors_cleaned))\n",
    "\n",
    "# Agregar columna de premios aleatorios (entre 0 y 10, con tendencia a números bajos)\n",
    "directors_cleaned['Awards'] = np.random.choice([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], size=len(directors_cleaned), p=[0.3, 0.2, 0.15, 0.1, 0.1, 0.05, 0.04, 0.03, 0.02, 0.01, 0.00])\n",
    "\n",
    "# Guardar el CSV de directores\n",
    "director_csv_path = \"Director_FINAL.csv\"\n",
    "directors_cleaned.to_csv(director_csv_path, index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías necesarias\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# Cargar el dataset movies_metadata.csv\n",
    "movies = pd.read_csv(\"movies_metadata.csv\", low_memory=False)\n",
    "\n",
    "# Asegurar que 'production_countries' sea string y reemplazar valores NaN correctamente\n",
    "movies['production_countries'] = movies['production_countries'].apply(lambda x: \"[]\" if pd.isna(x) else str(x))\n",
    "\n",
    "# Función para extraer países con validación adicional\n",
    "def extract_countries_safe(json_str, movie_id):\n",
    "    \"\"\"Extrae países de la columna production_countries asegurando formato correcto.\"\"\"\n",
    "    try:\n",
    "        country_list = json.loads(json_str.replace(\"'\", \"\\\"\")) if json_str.strip() not in [\"\", \"[]\", \"nan\"] else []\n",
    "        return [{\"CountryID\": country.get(\"iso_3166_1\", \"Unknown\"), \"Name\": country.get(\"name\", \"Unknown\"), \"MovieID\": movie_id} for country in country_list]\n",
    "    except (json.JSONDecodeError, TypeError):\n",
    "        return []\n",
    "\n",
    "# Extraer datos de países\n",
    "countries_data_safe = []\n",
    "for _, row in movies.iterrows():\n",
    "    countries_data_safe.extend(extract_countries_safe(row['production_countries'], row['id']))\n",
    "\n",
    "# Convertir a DataFrame y eliminar duplicados\n",
    "countries_cleaned_safe = pd.DataFrame(countries_data_safe).drop_duplicates()\n",
    "\n",
    "# Datos ficticios para población, idioma y ciudades\n",
    "population_data = {\n",
    "    \"United States\": 331000000, \"United Kingdom\": 67000000, \"France\": 65000000, \"Germany\": 83000000, \"Canada\": 38000000,\n",
    "    \"Australia\": 25000000, \"India\": 1390000000, \"Japan\": 126000000, \"Mexico\": 126000000, \"Brazil\": 213000000\n",
    "}\n",
    "\n",
    "language_data = {\n",
    "    \"United States\": \"English\", \"United Kingdom\": \"English\", \"France\": \"French\", \"Germany\": \"German\", \"Canada\": \"English, French\",\n",
    "    \"Australia\": \"English\", \"India\": \"Hindi, English\", \"Japan\": \"Japanese\", \"Mexico\": \"Spanish\", \"Brazil\": \"Portuguese\"\n",
    "}\n",
    "\n",
    "cities_data = {\n",
    "    \"United States\": \"New York, Los Angeles, Chicago\", \"United Kingdom\": \"London, Manchester, Birmingham\",\n",
    "    \"France\": \"Paris, Marseille, Lyon\", \"Germany\": \"Berlin, Munich, Hamburg\", \"Canada\": \"Toronto, Vancouver, Montreal\",\n",
    "    \"Australia\": \"Sydney, Melbourne, Brisbane\", \"India\": \"Mumbai, Delhi, Bangalore\", \"Japan\": \"Tokyo, Osaka, Kyoto\",\n",
    "    \"Mexico\": \"Mexico City, Guadalajara, Monterrey\", \"Brazil\": \"São Paulo, Rio de Janeiro, Brasília\"\n",
    "}\n",
    "\n",
    "# Asignar datos adicionales basados en el nombre del país\n",
    "countries_cleaned_safe['Population'] = countries_cleaned_safe['Name'].map(population_data).fillna(5000000)\n",
    "countries_cleaned_safe['Language'] = countries_cleaned_safe['Name'].map(language_data).fillna(\"Unknown\")\n",
    "countries_cleaned_safe['Cities'] = countries_cleaned_safe['Name'].map(cities_data).fillna(\"Unknown\")\n",
    "\n",
    "# Guardar el archivo corregido\n",
    "country_csv_path_safe = \"Country_FINAL3.csv\"\n",
    "countries_cleaned_safe.to_csv(country_csv_path_safe, index=False)\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Generar 50 nombres masculinos y 50 femeninos\n",
    "male_names = [\"John\", \"Michael\", \"David\", \"James\", \"Robert\", \"William\", \"Joseph\", \"Charles\", \"Thomas\", \"Daniel\",\n",
    "              \"Matthew\", \"Anthony\", \"Mark\", \"Donald\", \"Steven\", \"Paul\", \"Andrew\", \"Joshua\", \"Kenneth\", \"Kevin\",\n",
    "              \"Brian\", \"George\", \"Edward\", \"Ronald\", \"Timothy\", \"Jason\", \"Jeffrey\", \"Ryan\", \"Jacob\", \"Gary\",\n",
    "              \"Nicholas\", \"Eric\", \"Jonathan\", \"Stephen\", \"Larry\", \"Justin\", \"Scott\", \"Brandon\", \"Benjamin\", \"Samuel\",\n",
    "              \"Gregory\", \"Frank\", \"Alexander\", \"Raymond\", \"Patrick\", \"Jack\", \"Dennis\", \"Jerry\", \"Tyler\", \"Aaron\"]\n",
    "\n",
    "female_names = [\"Mary\", \"Patricia\", \"Jennifer\", \"Linda\", \"Elizabeth\", \"Barbara\", \"Susan\", \"Jessica\", \"Sarah\", \"Karen\",\n",
    "                \"Nancy\", \"Margaret\", \"Lisa\", \"Betty\", \"Dorothy\", \"Sandra\", \"Ashley\", \"Kimberly\", \"Emily\", \"Donna\",\n",
    "                \"Michelle\", \"Carol\", \"Amanda\", \"Melissa\", \"Deborah\", \"Stephanie\", \"Rebecca\", \"Sharon\", \"Laura\", \"Cynthia\",\n",
    "                \"Kathleen\", \"Amy\", \"Shirley\", \"Angela\", \"Helen\", \"Anna\", \"Brenda\", \"Pamela\", \"Nicole\", \"Samantha\",\n",
    "                \"Katherine\", \"Emma\", \"Ruth\", \"Christine\", \"Catherine\", \"Debra\", \"Rachel\", \"Carolyn\", \"Janet\", \"Maria\"]\n",
    "\n",
    "# Crear lista de usuarios\n",
    "user_data = []\n",
    "user_id = 1\n",
    "\n",
    "def generate_ratings(user_id, name, gender, age, movie_ids):\n",
    "    num_ratings = np.random.randint(2, 51)  # Entre 2 y 50 ratings por usuario\n",
    "    rated_movies = np.random.choice(movie_ids, size=num_ratings, replace=False)\n",
    "    ratings = np.round(np.random.uniform(1, 5, size=num_ratings), 2)  # Ratings entre 1 y 5\n",
    "    return [(user_id, name, gender, age, movie_id, rating) for movie_id, rating in zip(rated_movies, ratings)]\n",
    "\n",
    "# Obtener MovieIDs únicos\n",
    "movies = pd.read_csv(\"movies_metadata.csv\", low_memory=False)\n",
    "movies = movies.dropna(subset=[\"id\"])\n",
    "movies[\"id\"] = movies[\"id\"].astype(str).str.extract(r'(\\d+)').astype(float).dropna().astype(int)\n",
    "movie_ids = movies[\"id\"].unique()\n",
    "\n",
    "# Asignar usuarios con ratings\n",
    "for i, name in enumerate(male_names + female_names):\n",
    "    gender = \"Male\" if i < 50 else \"Female\"\n",
    "    age = np.random.randint(18, 65)  # Generar edades entre 18 y 65 años\n",
    "    ratings = generate_ratings(user_id, name, gender, age, movie_ids)\n",
    "    user_data.extend(ratings)\n",
    "    user_id += 1\n",
    "\n",
    "# Convertir a DataFrame y guardar\n",
    "users_df = pd.DataFrame(user_data, columns=[\"UserID\", \"Name\", \"Gender\", \"Age\", \"MovieID\", \"Rating\"])\n",
    "users_df.to_csv(\"User_FINAL4.csv\", index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Cargar el dataset de movies_metadata\n",
    "movies = pd.read_csv(\"movies_metadata.csv\", low_memory=False)\n",
    "\n",
    "# Asegurar que la columna 'genres' no tenga valores nulos\n",
    "movies['genres'] = movies['genres'].fillna('[]')\n",
    "\n",
    "# Extraer los géneros únicos\n",
    "genres_data = []\n",
    "for _, row in movies.iterrows():\n",
    "    try:\n",
    "        genre_list = json.loads(row['genres'].replace(\"'\", \"\\\"\")) if pd.notna(row['genres']) else []\n",
    "        for genre in genre_list:\n",
    "            genres_data.append({\"GenreID\": genre[\"id\"], \"Name\": genre[\"name\"]})\n",
    "    except json.JSONDecodeError:\n",
    "        continue\n",
    "\n",
    "# Convertir a DataFrame y eliminar duplicados\n",
    "genres_df = pd.DataFrame(genres_data).drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# Guardar como CSV\n",
    "genre_csv_path = \"Genre_FINAL.csv\"\n",
    "genres_df.to_csv(genre_csv_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Cargar los datos de movies_metadata.csv\n",
    "movies = pd.read_csv(\"movies_metadata.csv\", low_memory=False)\n",
    "\n",
    "# Expandir la columna JSON 'production_companies'\n",
    "import json\n",
    "\n",
    "def extract_companies(json_str, movie_id):\n",
    "    \"\"\"Extrae la lista de compañías de producción desde JSON.\"\"\"\n",
    "    try:\n",
    "        company_list = json.loads(json_str.replace(\"'\", \"\\\"\")) if pd.notna(json_str) else []\n",
    "        return [{\"CompanyID\": company[\"id\"], \"Name\": company[\"name\"], \"MovieID\": movie_id} for company in company_list]\n",
    "    except json.JSONDecodeError:\n",
    "        return []\n",
    "\n",
    "companies_data = []\n",
    "for _, row in movies.iterrows():\n",
    "    companies_data.extend(extract_companies(row['production_companies'], row['id']))\n",
    "\n",
    "# Convertir a DataFrame\n",
    "companies_df = pd.DataFrame(companies_data)\n",
    "\n",
    "# Asegurar que no haya IDs duplicados asignando CompanyID únicos\n",
    "companies_df.drop_duplicates(subset=['CompanyID'], inplace=True)\n",
    "\n",
    "# Generar datos ficticios para estudio, número de trabajadores y año de fundación\n",
    "np.random.seed(42)\n",
    "companies_df['Studio'] = np.random.choice([\"Warner Bros\", \"Universal Pictures\", \"Paramount\", \"Sony Pictures\", \"20th Century Fox\"], size=len(companies_df))\n",
    "companies_df['Num_Workers'] = np.random.randint(50, 10000, size=len(companies_df))\n",
    "companies_df['CreatedIn'] = np.random.randint(1920, 2022, size=len(companies_df))\n",
    "\n",
    "# Guardar en CSV\n",
    "company_csv_path = \"Company_FINAL.csv\"\n",
    "companies_df.to_csv(company_csv_path, index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modificar Movie CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# 📌 Cargar datos base\n",
    "movies = pd.read_csv(\"movies_metadata.csv\", low_memory=False)\n",
    "credits = pd.read_csv(\"credits.csv\", low_memory=False)\n",
    "keywords = pd.read_csv(\"keywords.csv\", low_memory=False)\n",
    "\n",
    "# 📌 Convertir MovieID a tipo entero donde sea posible\n",
    "movies[\"id\"] = pd.to_numeric(movies[\"id\"], errors=\"coerce\").astype(\"Int64\")\n",
    "credits[\"id\"] = pd.to_numeric(credits[\"id\"], errors=\"coerce\").astype(\"Int64\")\n",
    "keywords[\"id\"] = pd.to_numeric(keywords[\"id\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "# 📌 Función para extraer JSON y normalizarlo\n",
    "def extract_json_data(df, column_name, id_column):\n",
    "    extracted_data = []\n",
    "    for _, row in df.iterrows():\n",
    "        try:\n",
    "            if pd.notna(row[column_name]) and isinstance(row[column_name], str):\n",
    "                json_obj = json.loads(row[column_name].replace(\"'\", \"\\\"\"))\n",
    "                for obj in json_obj:\n",
    "                    obj[id_column] = row[id_column]\n",
    "                    extracted_data.append(obj)\n",
    "        except (json.JSONDecodeError, TypeError):\n",
    "            continue\n",
    "    return pd.DataFrame(extracted_data)\n",
    "\n",
    "# 📌 Obtener DirectorID desde el dataset credits.csv\n",
    "credits[\"crew\"] = credits[\"crew\"].fillna(\"[]\")\n",
    "crew_data = extract_json_data(credits, \"crew\", \"id\")\n",
    "directors = crew_data[crew_data[\"job\"] == \"Director\"][[\"id\", \"name\"]].rename(columns={\"id\": \"MovieID\", \"name\": \"DirectorID\"})\n",
    "\n",
    "# 📌 Obtener CountryID desde el dataset movies_metadata.csv\n",
    "movies[\"production_countries\"] = movies[\"production_countries\"].fillna(\"[]\")\n",
    "countries_data = extract_json_data(movies, \"production_countries\", \"id\")\n",
    "countries_data = countries_data.rename(columns={\"iso_3166_1\": \"CountryID\", \"id\": \"MovieID\"})\n",
    "\n",
    "# 📌 Obtener GenreID desde el dataset movies_metadata.csv\n",
    "movies[\"genres\"] = movies[\"genres\"].fillna(\"[]\")\n",
    "genres_data = extract_json_data(movies, \"genres\", \"id\")\n",
    "genres_data = genres_data.rename(columns={\"id\": \"MovieID\", \"name\": \"GenreID\"})\n",
    "\n",
    "# 📌 Obtener CompanyID desde el dataset movies_metadata.csv\n",
    "movies[\"production_companies\"] = movies[\"production_companies\"].fillna(\"[]\")\n",
    "companies_data = extract_json_data(movies, \"production_companies\", \"id\")\n",
    "companies_data = companies_data.rename(columns={\"id\": \"MovieID\", \"name\": \"CompanyID\"})\n",
    "\n",
    "# 📌 Obtener Keywords desde el dataset keywords.csv\n",
    "keywords[\"keywords\"] = keywords[\"keywords\"].fillna(\"[]\")\n",
    "keywords_data = extract_json_data(keywords, \"keywords\", \"id\")\n",
    "keywords_data = keywords_data.rename(columns={\"id\": \"MovieID\", \"name\": \"Keyword\"})\n",
    "\n",
    "# 📌 Seleccionar columnas necesarias para Movie.csv\n",
    "movies_selected = movies[[\"id\", \"title\", \"release_date\", \"runtime\", \"popularity\"]].copy()\n",
    "movies_selected.rename(columns={\n",
    "    \"id\": \"MovieID\",\n",
    "    \"title\": \"Title\",\n",
    "    \"release_date\": \"Released\",\n",
    "    \"runtime\": \"Runtime\",\n",
    "    \"popularity\": \"Popularity\"\n",
    "}, inplace=True)\n",
    "\n",
    "# 📌 Agregar las relaciones a Movie.csv\n",
    "movies_final = movies_selected.merge(directors, on=\"MovieID\", how=\"left\")\n",
    "movies_final = movies_final.merge(countries_data[[\"MovieID\", \"CountryID\"]], on=\"MovieID\", how=\"left\")\n",
    "movies_final = movies_final.merge(genres_data[[\"MovieID\", \"GenreID\"]], on=\"MovieID\", how=\"left\")\n",
    "movies_final = movies_final.merge(companies_data[[\"MovieID\", \"CompanyID\"]], on=\"MovieID\", how=\"left\")\n",
    "\n",
    "# 📌 Agregar Keywords (se agrupan todas las palabras clave de cada película en una lista separada por comas)\n",
    "keywords_aggregated = keywords_data.groupby(\"MovieID\")[\"Keyword\"].apply(lambda x: \", \".join(x)).reset_index()\n",
    "movies_final = movies_final.merge(keywords_aggregated, on=\"MovieID\", how=\"left\")\n",
    "\n",
    "# 📌 Guardar Movie_Final.csv\n",
    "movies_final.to_csv(\"Movie_Final_7.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
